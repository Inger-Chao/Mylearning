# get贴吧图片

哇。。在同学的公众号下面看到他找壁纸不想批量保存的脚本，感觉好酷啊，还有这种操作？。。源码看起来也很简单，因为自己也经常在贴吧找头像什么的于是试了一下

我用的是python3.5 同学用的2.7。
刚开始一直出现`no hosts given`这个bug,真是气死我了，我的url明明是对的啊。查了一下发现3.0后的版本`urlib`包下面没有`urlretrieve()`这个方法了QAQ

```python
urllib.request.urlretrieve(imgurl,'F:\img\%s.jpg' % x ) #2.7直接用urlib.urlretrieve()这个方法
```
接下来的一个问题就是程序执行完了然而我的路径下并没有东西。。然后开始逐行测试，`getPage()`方法没毛病，就是匹配不到网页里的jpg，又研究了一会正则表达式。。最后倒是搞好了嘿嘿嘿

最后附一下源码

```python
import re
import requests
import urllib.request
print("[+]please enter a url of tieba:")
url=input()
status=requests.session()
def getPage(status):
    text=status.get(url)
    html=text.text
    return html
page=getPage(status)
def getImage(html):
    reg = r'src=\\"(.*?\.jpg)'
    imgre = re.compile(reg)
    imglist = re.findall(imgre,html)
    finalist=[i.replace('\\','') for i in imglist]
   # print("finalist" + finalist)
    x=0
    for imgurl in finalist:
        urllib.request.urlretrieve(imgurl,'F:\img\%s.jpg' % x ) #2.7直接用urlib.urlretrieve()这个方法
        x+=1
html = getPage(status)
getImage(html)
print("[+]downloads the pictures...")
print("[+]finished!")
```

![这里写图片描述](http://img.blog.csdn.net/20170920231159056?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSm9raTIzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20170920231239063?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSm9raTIzMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

完美 最后感谢一下我的同学 出于礼貌帮他宣传一波公众号：UniverseIDthree

----------------------------------------------------------
附上他的文章[链接](http://mp.weixin.qq.com/s/KM44nypPm2kl6__sr4m6ZA)
